
the foundation of every great pipeline is clean, efficient and testable
the purpose of this module is to establish a solid python foundation tailored specifically for the needs of dataops workflows

## Requirements 
- write performant python code using numpy and pandas
- manage and version code with git using dataops best practices
- test and package their preprocessing pipelines for reproducibility and automation
- enhance performance and optimize memory
### Technical skills gained
- mastery of pandas and numpy for data engineering tasks
- efficient data handling through memory optimizations and vectorized operations
- building modular and testable preprocessing pipelines
- managing collaborative workflows with git and github
- ensuring code quality and reproducibility via packaging and environment isolation

### tools and techs
python 3.10, pandas and numpy, git and github, poetry, pip venv uv, pytest, jupyer lab or vs code