---
title: Notes
date: 2024-03-24
tags: [DataOps, DevOps, Data Engineering]
---

## What is DevOps?

**[[DataOps]]** is a discipline at the intersection of data engineering, DevOps and agile analytics. its main focus is creating robust, automated, production-grade data pipelines that delivers clean, governed and ML-ready data at scale.

Same we SWE, we use version control, testing, continuous delivery, observability and feedback loops.


## Who is the DataOps Engineer?

- Build pipelines that transform raw, messy data into feature-rich, trustworthy assets
- Ensure that these pipelines are automated, versioned, tested and observed
- As a bridge between infrastructure, data science and product teams

## How to stand out?

- Think systems, not scripts: architect a solution, employ modular design, version control and orchestration tools (IE Airflow) to create end-to-end systems.
- Automate everything: script anything that would need to be ran twice or more, from data validation to deployment (use CI/CD, containerization and job schedulers).
- Build for quality: test frequently, schema check and observe to ensure pipelines are not just functional but trustworthy and production ready.
- Collab like a SDE: git workflows, code reviews, [[Reproducible environments]], treat pipelines like prod code
- Understand the end users: be it for a dashboard or a data scientist, produced data should be ready to use and easy to trust
- Stay curious: read docs, collab to open source projects, never stop learning
## Soft skills

- Communication
- Analytical thinking
- Collaboration
- Patience and rigor

## Pillars of DataOps

- Collaboration
- Automation
- CI/CD
- Metrics and Monitoring
- Data Quality and Governance



